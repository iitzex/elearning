import os
import re
import requests
from bs4 import BeautifulSoup


def extract_course_info(file_path):
    """å¾ä¸»é é¢ HTML æå–èª²ç¨‹åç¨±ã€é€£çµå’Œå®Œæˆç‹€æ…‹"""
    print(f"[è®€å–æª”æ¡ˆ] {file_path}")
    with open(file_path, 'r', encoding='utf-8') as f:
        html_content = f.read()

    soup = BeautifulSoup(html_content, 'html.parser')
    courses = []

    # å°‹æ‰¾åŒ…å«èª²ç¨‹åˆ—çš„è¡¨æ ¼ä¸»é«”
    tbody = soup.find('tbody', class_='table__tbody')
    if tbody:
        rows = tbody.find_all('tr', class_='table-row')
        for row in rows:
            course_cell = row.find('td', {'data-column': 'èª²ç¨‹åç¨±'})
            hours_cell = row.find('td', {'data-column': 'èªè­‰æ™‚æ•¸'})
            study_time_cell = row.find('td', {'data-column': 'ä¿®èª²æ™‚é–“'})
            completion_cell = row.find('td', {'data-column': 'èª²ç¨‹å®Œæˆèˆ‡å¦'})

            if course_cell:
                link_tag = course_cell.find('a', class_='href')
                if link_tag:
                    course_name = link_tag.get_text(strip=True)
                    course_link = link_tag.get('href')

                    # æå–èªè­‰æ™‚æ•¸
                    hours = ""
                    if hours_cell:
                        hours_p = hours_cell.find('p')
                        if hours_p:
                            hours = hours_p.get_text(strip=True)

                    # æå–ä¿®èª²æ™‚é–“ï¼ˆå·²ä¸Šèª²ç´¯è¨ˆæ™‚é–“ï¼‰
                    study_time = ""
                    if study_time_cell:
                        study_time_link = study_time_cell.find('a')
                        if study_time_link:
                            study_time = study_time_link.get_text(strip=True)

                    # æå–å®Œæˆç‹€æ…‹
                    completion_status = "æœªçŸ¥"
                    if completion_cell:
                        completion_p = completion_cell.find('p')
                        if completion_p:
                            completion_status = completion_p.get_text(strip=True)

                    courses.append({
                        'name': course_name,
                        'link': course_link,
                        'hours': hours,
                        'study_time': study_time,
                        'completion_status': completion_status
                    })
    print(f"[è³‡è¨Š] æ‰¾åˆ° {len(courses)} å€‹èª²ç¨‹")
    return courses


def login_and_get_session(username, password):
    """ç™»å…¥ä¸¦è¿”å› session å°è±¡"""
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })

    login_page_url = "https://elearning.taipei/mpage/login"
    login_do_url = "https://elearning.taipei/mpage/do-login"
    captcha_img_url = "https://elearning.taipei/mpage/captcha"

    print(f"[ç™»å…¥] æ­£åœ¨æº–å‚™ç™»å…¥å¸³è™Ÿ: {username}...")

    try:
        # 1. ç²å– CSRF token
        response = session.get(login_page_url)
        soup = BeautifulSoup(response.text, 'html.parser')
        token_input = soup.find('input', {'name': '_token'})

        if not token_input:
            print("[è­¦å‘Š] æ‰¾ä¸åˆ° CSRF tokenã€‚")
            token = ""
        else:
            token = token_input['value']

        # 2. ç²å–é©—è­‰ç¢¼åœ–ç‰‡
        print("[è³‡è¨Š] æ­£åœ¨ä¸‹è¼‰é©—è­‰ç¢¼...")
        captcha_resp = session.get(captcha_img_url)
        with open("captcha.png", "wb") as f:
            f.write(captcha_resp.content)
        
        # 3. é–‹å•Ÿé©—è­‰ç¢¼åœ–ç‰‡ (é©ç”¨æ–¼ Mac)
        import subprocess
        subprocess.run(["open", "captcha.png"])
        
        # 4. åœä¸‹ç­‰å¾…ç”¨æˆ¶è¼¸å…¥
        captcha_code = input("\n[ç­‰å¾…è¼¸å…¥] è«‹æŸ¥çœ‹é–‹å•Ÿçš„ captcha.png ä¸¦åœ¨æ­¤è¼¸å…¥é©—è­‰ç¢¼: ")

        # æº–å‚™ç™»å…¥è³‡æ–™
        payload = {
            '_token': token,
            'username': username,
            'password': password,
            'captcha': captcha_code
        }

        # 5. åŸ·è¡Œç™»å…¥
        response = session.post(login_do_url, data=payload)

        # æª¢æŸ¥æ˜¯å¦ç™»å…¥æˆåŠŸ
        if "logout" in response.text.lower() or "å€‹äººé¸å–®" in response.text or "è¨ªå®¢" not in response.text:
            print("[æˆåŠŸ] ç™»å…¥æˆåŠŸ!")
        else:
            print("[å¤±æ•—] ç™»å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¸³è™Ÿå¯†ç¢¼æˆ–é©—è­‰ç¢¼æ˜¯å¦æ­£ç¢ºã€‚")
            # åˆªé™¤å·²ä½¿ç”¨çš„é©—è­‰ç¢¼åœ–ç‰‡
            if os.path.exists("captcha.png"):
                os.remove("captcha.png")
            return login_and_get_session(username, password) # å˜—è©¦é‡æ–°ç™»å…¥

        # ç™»å…¥æˆåŠŸå¾Œåˆªé™¤é©—è­‰ç¢¼åœ–ç‰‡
        if os.path.exists("captcha.png"):
            os.remove("captcha.png")
            
        return session

    except Exception as e:
        print(f"[éŒ¯èª¤] ç™»å…¥éç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸: {e}")
        return session


def get_scorm_links_with_session(session, url):
    """ä½¿ç”¨ session ç²å–é é¢å…§å®¹ï¼Œè™•ç†è·³è½‰ä¸¦è§£æ SCORM é€£çµ"""
    try:
        print(f"   [è®€å–ä¸­] {url}...")
        response = session.get(url)
        content = response.text

        # è™•ç† <script>location.href = "/elearn/courseinfo/so.php?v=5508";</script> å½¢å¼çš„è·³è½‰
        js_redirect = re.search(
            r'location\.href\s*=\s*["\']([^"\']+)["\']', content)
        if js_redirect:
            redirect_url = js_redirect.group(1)
            if redirect_url.startswith('/'):
                redirect_url = "https://ap2.elearning.taipei" + redirect_url
            print(f"   [è·³è½‰ä¸­] {redirect_url}...")
            response = session.get(redirect_url)
            content = response.text

        soup = BeautifulSoup(content, 'html.parser')
        scorm_links = []

        # ç›®æ¨™ç¶²å€æ¨¡å¼
        pattern = 'https://ap2.elearning.taipei/elearn/mod/scorm/view.php?id='

        # 1. å°‹æ‰¾æ‰€æœ‰ <a> æ¨™ç±¤
        links = soup.find_all('a', href=True)
        for link in links:
            href = link['href']
            if href.startswith(pattern):
                scorm_links.append(href)

        # 2. æ­£å‰‡è¡¨é”å¼å‚™æ¡ˆ (æœå°‹æ•´å€‹å…§å®¹)
        matches = re.findall(
            rf'https://ap2\.elearning\.taipei/elearn/mod/scorm/view\.php\?id=\d+', content)
        scorm_links.extend(matches)

        return sorted(list(set(scorm_links)))  # å»é‡ä¸¦æ’åº
    except Exception as e:
        print(f"   [éŒ¯èª¤] è§£æéç¨‹ç™¼ç”Ÿå•é¡Œ: {e}")
        return []


def check_course_completion(session, course_url):
    """æª¢æŸ¥èª²ç¨‹æ˜¯å¦å·²å®Œæˆï¼Œä¸¦æå–å·²ä¸Šèª²æ™‚é–“"""
    try:
        response = session.get(course_url)
        content = response.text
        
        # è™•ç† JavaScript è·³è½‰
        js_redirect = re.search(r'location\.href\s*=\s*["\']([^"\']+)["\']', content)
        if js_redirect:
            redirect_url = js_redirect.group(1)
            if redirect_url.startswith('/'):
                redirect_url = "https://ap2.elearning.taipei" + redirect_url
            response = session.get(redirect_url)
            content = response.text
        
        soup = BeautifulSoup(content, 'html.parser')
        
        # æå–å·²ä¸Šèª²æ™‚é–“
        study_times = []
        
        # æ–¹æ³•1: æŸ¥æ‰¾æ™‚é–“è¨˜éŒ„ï¼ˆå¸¸è¦‹æ ¼å¼ï¼šYYYY-MM-DD HH:MM æˆ– YYYY/MM/DDï¼‰
        time_patterns = [
            r'\d{4}[-/]\d{2}[-/]\d{2}\s+\d{2}:\d{2}',  # 2024-01-15 14:30
            r'\d{4}[-/]\d{2}[-/]\d{2}',  # 2024-01-15
        ]
        
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            study_times.extend(matches)
        
        # æ–¹æ³•2: æŸ¥æ‰¾åŒ…å«"ä¸Šèª²æ™‚é–“"ã€"å­¸ç¿’æ™‚é–“"ã€"å®Œæˆæ™‚é–“"ç­‰é—œéµå­—çš„å€åŸŸ
        time_keywords = ['ä¸Šèª²æ™‚é–“', 'å­¸ç¿’æ™‚é–“', 'å®Œæˆæ™‚é–“', 'è§€çœ‹æ™‚é–“', 'å­¸ç¿’æ—¥æœŸ']
        for keyword in time_keywords:
            # æŸ¥æ‰¾é—œéµå­—å¾Œé¢çš„æ™‚é–“
            keyword_pattern = keyword + r'[ï¼š:]\s*([^\n<]+)'
            matches = re.findall(keyword_pattern, content)
            study_times.extend(matches)
        
        # æ–¹æ³•3: å¾è¡¨æ ¼ä¸­æå–æ™‚é–“è³‡è¨Š
        tables = soup.find_all('table')
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                for cell in cells:
                    cell_text = cell.get_text(strip=True)
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ ¼å¼
                    for pattern in time_patterns:
                        matches = re.findall(pattern, cell_text)
                        study_times.extend(matches)
        
        # å»é‡ä¸¦æ’åº
        study_times = sorted(list(set(study_times)))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å®Œæˆæ¨™è¨˜
        progress = None
        is_completed = None
        
        # æ–¹æ³•1: æŸ¥æ‰¾é€²åº¦ç™¾åˆ†æ¯”
        progress_indicators = soup.find_all(string=re.compile(r'(\d+)%'))
        for indicator in progress_indicators:
            match = re.search(r'(\d+)%', indicator)
            if match:
                progress = int(match.group(1))
                if progress == 100:
                    is_completed = True
                else:
                    is_completed = False
                break
        
        # æ–¹æ³•2: æŸ¥æ‰¾å®Œæˆç‹€æ…‹æ–‡å­—
        if is_completed is None:
            completion_texts = ['å·²å®Œæˆ', 'å®Œæˆ', 'Completed', '100%']
            for text in completion_texts:
                if text in content:
                    is_completed = True
                    progress = 100
                    break
        
        # æ–¹æ³•3: æŸ¥æ‰¾æœªå®Œæˆç‹€æ…‹
        if is_completed is None:
            incomplete_texts = ['æœªå®Œæˆ', 'é€²è¡Œä¸­', 'In Progress']
            for text in incomplete_texts:
                if text in content:
                    is_completed = False
                    if progress is None:
                        progress = 0
                    break
        
        # å°‹æ‰¾ SCORM é€£çµ
        scorm_link = None
        # ä¾ç…§ä½¿ç”¨è€…æç¤ºï¼Œæœå°‹åŒ…å« "/elearn/mod/scorm/view.ph" çš„ç¶²å€
        scorm_pattern = "/elearn/mod/scorm/view.ph"
        
        # 1. å¾æ‰€æœ‰ <a> æ¨™ç±¤å°‹æ‰¾
        links = soup.find_all('a', href=True)
        for link in links:
            href = link['href']
            if scorm_pattern in href:
                if href.startswith('/'):
                    scorm_link = "https://ap2.elearning.taipei" + href
                else:
                    scorm_link = href
                break
        
        # 2. å¦‚æœæ²’æ‰¾åˆ°ï¼Œç”¨æ­£å‰‡è¡¨é”å¼æœæ•´å€‹å…§å®¹ï¼ˆåŒ…å« JavaScript ä¸­çš„ç¶²å€ï¼‰
        if not scorm_link:
            # æœå°‹åŒ…å« scorm/view.php?id= æ•¸å­—çš„æ¨¡å¼
            matches = re.findall(r'https?://[^\s"\'<>]+/elearn/mod/scorm/view\.php\?id=\d+', content)
            if not matches:
                matches = re.findall(r'["\'](/elearn/mod/scorm/view\.php\?id=\d+)["\']', content)
                if matches:
                    scorm_link = "https://ap2.elearning.taipei" + matches[0]
            else:
                scorm_link = matches[0]
        
        if not scorm_link:
             # å†è©¦ä¸€æ¬¡æ›´å»£æ³›çš„æœå°‹
             matches = re.findall(r'[/a-zA-Z0-9\._\-]*scorm/view\.php\?id=\d+', content)
             if matches:
                 if matches[0].startswith('/'):
                     scorm_link = "https://ap2.elearning.taipei" + matches[0]
                 elif matches[0].startswith('http'):
                     scorm_link = matches[0]
                 else:
                     scorm_link = "https://ap2.elearning.taipei/elearn/mod/" + matches[0]

        if scorm_link:
            print(f"   [æ‰¾åˆ° SCORM é€£çµ] {scorm_link}")
        else:
            print(f"   [è­¦å‘Š] æ‰¾ä¸åˆ° SCORM é€£çµ")

        return is_completed, progress, study_times, scorm_link
        
    except Exception as e:
        print(f"   [éŒ¯èª¤] æª¢æŸ¥èª²ç¨‹æ™‚ç™¼ç”Ÿå•é¡Œ: {e}")
        return None, None, [], None


def load_config(config_file="id.confg"):
    """å¾è¨­å®šæª”è®€å–å¸³è™Ÿå¯†ç¢¼"""
    config = {}
    if os.path.exists(config_file):
        with open(config_file, "r", encoding="utf-8") as f:
            for line in f:
                if "=" in line:
                    key, value = line.strip().split("=", 1)
                    config[key] = value
    return config


if __name__ == '__main__':
    # å¾ id.confg è®€å–å¸³è™Ÿå¯†ç¢¼
    config = load_config()
    USER_ID = config.get("USER_ID", "")
    USER_PW = config.get("USER_PW", "")

    if not USER_ID or not USER_PW:
        print("éŒ¯èª¤: è«‹ç¢ºä¿ id.confg ä¸­åŒ…å« USER_ID å’Œ USER_PW")
        exit(1)

    main_file = 'course.html'
    if not os.path.exists(main_file):
        print(f"éŒ¯èª¤: åœ¨æ­¤è·¯å¾‘æ‰¾ä¸åˆ°æª”æ¡ˆ '{main_file}'")
        exit(1)
    
    # æå–èª²ç¨‹è³‡è¨Š
    print("=" * 60)
    print("æ­£åœ¨æå–èª²ç¨‹è³‡è¨Š...")
    print("=" * 60)
    courses = extract_course_info(main_file)
    
    # å…ˆæ ¹æ“š HTML ä¸­çš„å®Œæˆç‹€æ…‹é€²è¡Œåˆæ­¥åˆ†é¡
    print("\n" + "=" * 60)
    print("æ­£åœ¨åˆ†æèª²ç¨‹ç‹€æ…‹...")
    print("=" * 60)
    
    incomplete_courses = []
    completed_courses = []
    unknown_courses = []
    
    # çµ±è¨ˆèª²ç¨‹ç‹€æ…‹
    for course in courses:
        status = course.get('completion_status', 'æœªçŸ¥')
        print(f"\nèª²ç¨‹: {course['name']}")
        print(f"   ç‹€æ…‹: {status}")
        
        if status == 'å·²å®Œæˆ':
            completed_courses.append({
                'name': course['name'],
                'link': course['link'],
                'hours': course['hours'],
                'study_time': course.get('study_time', ''),
                'progress': 100,
                'study_times': []
            })
        elif status == 'æœªå®Œæˆ':
            incomplete_courses.append({
                'name': course['name'],
                'link': course['link'],
                'hours': course['hours'],
                'study_time': course.get('study_time', ''),
                'progress': None,
                'study_times': []
            })
        else:
            unknown_courses.append({
                'name': course['name'],
                'link': course['link'],
                'hours': course['hours'],
                'study_time': course.get('study_time', ''),
                'progress': None,
                'study_times': []
            })
    
    # å¦‚æœæœ‰æœªå®Œæˆçš„èª²ç¨‹ï¼Œç™»å…¥ä¸¦ç²å–è©³ç´°è³‡è¨Š
    if incomplete_courses:
        print("\n" + "=" * 60)
        print("æ­£åœ¨ç™»å…¥å­¸ç¿’å¹³å°ç²å–è©³ç´°è³‡è¨Š...")
        print("=" * 60)
        session = login_and_get_session(USER_ID, USER_PW)
        
        print("\n" + "=" * 60)
        print("æ­£åœ¨æª¢æŸ¥æœªå®Œæˆèª²ç¨‹çš„è©³ç´°è³‡è¨Š...")
        print("=" * 60)
        
        for i, course in enumerate(incomplete_courses, 1):
            print(f"\n[{i}/{len(incomplete_courses)}] æª¢æŸ¥: {course['name']}")
            is_completed, progress, study_times, scorm_link = check_course_completion(session, course['link'])
            
            # æ›´æ–°èª²ç¨‹è³‡è¨Š
            course['progress'] = progress if progress is not None else 0
            course['study_times'] = study_times
            if scorm_link:
                course['scorm_link'] = scorm_link
            
            if study_times:
                print(f"   ğŸ“… ä¸Šèª²æ™‚é–“: {', '.join(study_times[:3])}{'...' if len(study_times) > 3 else ''}")
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "=" * 60)
    print("æª¢æŸ¥çµæœæ‘˜è¦")
    print("=" * 60)
    print(f"ç¸½èª²ç¨‹æ•¸: {len(courses)}")
    print(f"å·²å®Œæˆ: {len(completed_courses)}")
    print(f"æœªå®Œæˆ: {len(incomplete_courses)}")
    print(f"ç‹€æ…‹æœªçŸ¥: {len(unknown_courses)}")
    
    if incomplete_courses:
        print("\n" + "=" * 60)
        print("æœªå®Œæˆçš„èª²ç¨‹åˆ—è¡¨")
        print("=" * 60)
        for i, course in enumerate(incomplete_courses, 1):
            print(f"\n{i}. {course['name']}")
            print(f"   èªè­‰æ™‚æ•¸: {course['hours']} å°æ™‚")
            if course.get('study_time'):
                print(f"   ä¿®èª²æ™‚é–“: {course['study_time']}")
            if course['progress'] is not None:
                print(f"   é€²åº¦: {course['progress']}%")
            if course.get('study_times'):
                print(f"   ğŸ“… ä¸Šèª²æ™‚é–“: {', '.join(course['study_times'])}")
            print(f"   é€£çµ: {course['link']}")
    
    if unknown_courses:
        print("\n" + "=" * 60)
        print("ç‹€æ…‹æœªçŸ¥çš„èª²ç¨‹åˆ—è¡¨")
        print("=" * 60)
        for i, course in enumerate(unknown_courses, 1):
            print(f"\n{i}. {course['name']}")
            print(f"   æ™‚æ•¸: {course['hours']}")
            print(f"   é€£çµ: {course['link']}")
    
    # å„²å­˜çµæœåˆ°æª”æ¡ˆ
    with open('incomplete_courses.txt', 'w', encoding='utf-8') as f:
        f.write("æœªå®Œæˆçš„èª²ç¨‹åˆ—è¡¨\n")
        f.write("=" * 60 + "\n\n")
        for i, course in enumerate(incomplete_courses, 1):
            f.write(f"{i}. {course['name']}\n")
            f.write(f"   èªè­‰æ™‚æ•¸: {course['hours']} å°æ™‚\n")
            if course.get('study_time'):
                f.write(f"   ä¿®èª²æ™‚é–“: {course['study_time']}\n")
            if course['progress'] is not None:
                f.write(f"   é€²åº¦: {course['progress']}%\n")
            if course.get('study_times'):
                f.write(f"   ä¸Šèª²æ™‚é–“: {', '.join(course['study_times'])}\n")
            # å„ªå…ˆå¯«å…¥ SCORM é€£çµï¼Œè‹¥ç„¡å‰‡å¯«å…¥åŸå§‹é€£çµ
            link_to_save = course.get('scorm_link', course['link'])
            f.write(f"   é€£çµ: {link_to_save}\n\n")
    
    print("\n" + "=" * 60)
    print("çµæœå·²å„²å­˜è‡³ incomplete_courses.txt")
    print("=" * 60)
